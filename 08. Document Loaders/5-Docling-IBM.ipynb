{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Announcement-on-ML\n",
    "<a href='http://www.kgptalkie.com' target=\"_blank\"> <img src='https://github.com/laxmimerit/Important-Announcement-on-ML/raw/master/kgptalkie_strips.png'/></a>\n",
    "\n",
    "# ML Resources\n",
    "|  ML Course | Description |\n",
    "|:---|:---|\n",
    "| [**Deploy LLM App with Ollama and Langchain in Production**](https://www.udemy.com/course/ollama-and-langchain/?referralCode=7F4C0C7B8CF223BA9327) | Master Langchain v0.3, Private Chatbot, Deploy LLM App.  Ollama, LLAMA, LLAMA 3.2, FAISS, RAG, Deploy RAG, Gen AI, LLM|\n",
    "| [**Fine Tuning LLM with HuggingFace Transformers for NLP**](https://www.udemy.com/course/fine-tuning-llm-with-hugging-face-transformers/?referralCode=6DEB3BE17C2644422D8E) | Learn how to fine tune LLM with custom dataset. You will learn basics of transformers then fine tune LLM|\n",
    "| [**Data Visualization in Python Masterclassâ„¢: Beginners to Pro**](https://bit.ly/udemy95off_kgptalkie) |  Learn to build Machine Learning and Deep Learning models using Python and its libraries like Scikit-Learn, Keras, and TensorFlow. |\n",
    "| [**Python for Machine Learning: A Step-by-Step Guide**](https://bit.ly/ml-ds-project) | Learn to build Machine Learning and Deep Learning models using Python and its libraries like Scikit-Learn, Keras, and TensorFlow. |\n",
    "| [**Deep Learning for Beginners with Python**](https://bit.ly/dl-with-python) | Neural Networks, TensorFlow, ANN, CNN, RNN, LSTM, Transfer Learning and Much More. |\n",
    "| [**Python for Linear Regression in Machine Learning**](https://bit.ly/regression-python) | Learn to build Linear Regression models using Python and its libraries like Scikit-Learn. |\n",
    "| [**Introduction to Spacy 3 for Natural Language Processing**](https://bit.ly/spacy-intro) | Learn to build Natural Language Processing models using Python and its libraries like Spacy. |\n",
    "| [**Advanced Machine Learning and Deep Learning Projects**](https://bit.ly/kgptalkie_ml_projects) | Learn to build Advanced Machine Learning and Deep Learning models using Python and transformer models like BERT, GPT-2, and XLNet. |\n",
    "| [**Natural Language Processing in Python for Beginners**](https://bit.ly/intro_nlp) | Learn to build Natural Language Processing Projects using Spacy, NLTK, and Gensim, and transformer models like BERT, GPT-2, and XLNet. |\n",
    "| [**Deployment of Machine Learning Models in Production in Python**](https://bit.ly/bert_nlp) |  Learn to deploy Machine Learning and Deep Learning models using Python and its libraries like Flask, Streamlit, and NGINX. |\n",
    "| [**R 4.0 Programming for Data Science - Beginners to Pro**](https://bit.ly/r4-ml) | Learn to build Machine Learning and Deep Learning models using R and its libraries like caret, tidyverse, and keras. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Markdown Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-20 19:15:57,389 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-10-20 19:15:57,408 - INFO - Going to convert document batch...\n",
      "2025-10-20 19:15:57,409 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 4f2edc0f7d9bb60b38ebfecf9a2609f5\n",
      "2025-10-20 19:15:57,420 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-10-20 19:15:57,422 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
      "2025-10-20 19:15:57,434 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-10-20 19:15:57,436 - INFO - Registered ocr engines: ['auto', 'easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
      "2025-10-20 19:15:57,697 - INFO - Accelerator device: 'cuda:0'\n",
      "\u001b[32m[INFO] 2025-10-20 19:15:57,708 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-20 19:15:57,712 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-20 19:15:57,713 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-20 19:15:57,760 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-20 19:15:57,762 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-20 19:15:57,762 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-20 19:15:57,788 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-20 19:15:57,794 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-20 19:15:57,794 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "2025-10-20 19:15:57,860 - INFO - Auto OCR model selected rapidocr with onnxruntime.\n",
      "2025-10-20 19:15:57,865 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-10-20 19:15:58,765 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-10-20 19:15:59,058 - INFO - Processing document Apple-10-Q-2025-Q1.pdf\n",
      "2025-10-20 19:16:13,525 - INFO - Finished converting document Apple-10-Q-2025-Q1.pdf in 16.14 sec.\n"
     ]
    }
   ],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "converter = DocumentConverter()\n",
    "\n",
    "# Step 2: Convert document (works with PDF, DOCX, PPTX)\n",
    "file_path  = Path(\"data/Apple-10-Q-2025-Q1.pdf\")\n",
    "result = converter.convert(file_path)\n",
    "markdown = result.document.export_to_markdown()\n",
    "\n",
    "# Step 4: Print or save\n",
    "# print(markdown)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(\"docling\", exist_ok=True)\n",
    "with open(f\"docling/{file_path.stem}.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-20 19:16:13,617 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-10-20 19:16:13,619 - INFO - Going to convert document batch...\n",
      "2025-10-20 19:16:13,619 - INFO - Processing document scansmpl.pdf\n",
      "2025-10-20 19:16:20,342 - INFO - Finished converting document scansmpl.pdf in 6.73 sec.\n"
     ]
    }
   ],
   "source": [
    "file_path  = Path(\"data/scansmpl.pdf\")\n",
    "result = converter.convert(file_path)\n",
    "markdown = result.document.export_to_markdown()\n",
    "\n",
    "with open(f\"docling/{file_path.stem}.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-20 19:16:20,364 - INFO - detected formats: [<InputFormat.DOCX: 'docx'>]\n",
      "2025-10-20 19:16:20,368 - INFO - Going to convert document batch...\n",
      "2025-10-20 19:16:20,368 - INFO - Initializing pipeline for SimplePipeline with options hash 995a146ad601044538e6a923bea22f4e\n",
      "2025-10-20 19:16:20,368 - INFO - Processing document job_description.docx\n",
      "2025-10-20 19:16:20,385 - INFO - Finished converting document job_description.docx in 0.05 sec.\n"
     ]
    }
   ],
   "source": [
    "file_path  = Path(\"data/job_description.docx\")\n",
    "result = converter.convert(file_path)\n",
    "markdown = result.document.export_to_markdown()\n",
    "\n",
    "with open(f\"docling/{file_path.stem}.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-20 19:16:20,416 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-10-20 19:16:20,424 - INFO - Going to convert document batch...\n",
      "2025-10-20 19:16:20,424 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 4f2edc0f7d9bb60b38ebfecf9a2609f5\n",
      "2025-10-20 19:16:20,425 - INFO - Accelerator device: 'cuda:0'\n",
      "\u001b[32m[INFO] 2025-10-20 19:16:20,437 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-20 19:16:20,440 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-20 19:16:20,440 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-20 19:16:20,481 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-20 19:16:20,482 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-20 19:16:20,482 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-20 19:16:20,505 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-20 19:16:20,510 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-20 19:16:20,511 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "2025-10-20 19:16:20,574 - INFO - Auto OCR model selected rapidocr with onnxruntime.\n",
      "2025-10-20 19:16:20,574 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-10-20 19:16:21,347 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-10-20 19:16:21,615 - INFO - Processing document Apple-10-Q-2025-Q1.pdf\n",
      "2025-10-20 19:16:36,718 - INFO - Finished converting document Apple-10-Q-2025-Q1.pdf in 16.30 sec.\n",
      "2025-10-20 19:16:36,720 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-20 19:16:36,737 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-20 19:16:36,740 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-20 19:16:36,741 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-20 19:16:36,742 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-20 19:16:36,744 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-20 19:16:36,746 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-20 19:16:36,747 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-20 19:16:36,748 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-20 19:16:36,749 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-20 19:16:36,751 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-20 19:16:36,754 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-20 19:16:36,756 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-20 19:16:36,756 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-20 19:16:36,758 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-20 19:16:36,759 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-20 19:16:36,760 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-20 19:16:36,761 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-20 19:16:36,762 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-20 19:16:36,763 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-20 19:16:36,764 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-20 19:16:36,766 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-20 19:16:36,767 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-20 19:16:36,768 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-20 19:16:36,769 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"docling/tables\", exist_ok=True)\n",
    "# Step 1: Convert document\n",
    "converter = DocumentConverter()\n",
    "\n",
    "file_path = Path(\"data/Apple-10-Q-2025-Q1.pdf\")\n",
    "result = converter.convert(file_path)\n",
    "\n",
    "# Step 2: Loop through tables\n",
    "for i, table in enumerate(result.document.tables):\n",
    "    # Convert table to pandas DataFrame\n",
    "    df = table.export_to_dataframe()\n",
    "    \n",
    "    # Save as CSV\n",
    "    df.to_csv(f\"docling/tables/{file_path.stem}_table_{i+1}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Figures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-20 19:16:36,795 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-10-20 19:16:36,797 - INFO - Going to convert document batch...\n",
      "2025-10-20 19:16:36,798 - INFO - Initializing pipeline for StandardPdfPipeline with options hash e13f1ccd8170a627ad25ebdda600bbe2\n",
      "2025-10-20 19:16:36,798 - INFO - Accelerator device: 'cuda:0'\n",
      "\u001b[32m[INFO] 2025-10-20 19:16:36,809 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-20 19:16:36,812 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-20 19:16:36,813 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-20 19:16:36,861 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-20 19:16:36,863 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-20 19:16:36,863 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-20 19:16:36,895 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-20 19:16:36,902 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-20 19:16:36,903 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "2025-10-20 19:16:36,990 - INFO - Auto OCR model selected rapidocr with onnxruntime.\n",
      "2025-10-20 19:16:36,991 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-10-20 19:16:37,784 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-10-20 19:16:38,045 - INFO - Processing document sample_textbook.pdf\n",
      "2025-10-20 19:16:40,756 - INFO - Finished converting document sample_textbook.pdf in 3.95 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved figure_1.png\n",
      "Saved figure_2.png\n",
      "Saved figure_3.png\n"
     ]
    }
   ],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.document_converter import PdfFormatOption\n",
    "\n",
    "os.makedirs(\"docling/figures\", exist_ok=True)\n",
    "\n",
    "# Step 1: Enable image extraction\n",
    "pipeline_options = PdfPipelineOptions()\n",
    "pipeline_options.generate_picture_images = True\n",
    "pipeline_options.images_scale = 3.0\n",
    "\n",
    "# Step 2: Create converter\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Step 3: Convert document\n",
    "file_path = Path(\"data/sample_textbook.pdf\")\n",
    "result = converter.convert(file_path)\n",
    "\n",
    "# Step 4: Save each figure\n",
    "for i, picture in enumerate(result.document.pictures):\n",
    "    image = picture.get_image(result.document)\n",
    "    image.save(f\"docling/figures/{file_path.stem}_figure_{i+1}.png\")\n",
    "    print(f\"Saved figure_{i+1}.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
