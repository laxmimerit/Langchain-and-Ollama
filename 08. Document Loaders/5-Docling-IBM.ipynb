{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ¤– LLM and AI Agent Development Courses\n",
    "\n",
    "| Course | Description | Enroll |\n",
    "|--------|-------------|---------|\n",
    "| **ðŸŽ¯ Master OpenAI Agent Builder** | Build and deploy AI agents visually using OpenAI Agent Builder, ChatKit, RAG, Chatbot, AI Assistant with MCP, AWS, RDS MySQL | [Enroll Now](https://www.udemy.com/course/master-openai-agent-builder-low-code-ai-projects-workflow/?referralCode=B0B67D18B1013E488FB7) |\n",
    "| **ðŸ”¥ MCP Mastery** | Build MCP servers & clients with Python, Streamlit, ChromaDB, LangChain, LangGraph agents, and Ollama integrations | [Enroll Now](https://www.udemy.com/course/mcp-mastery-build-ai-apps-with-claude-langchain-and-ollama/?referralCode=31C17C306A59601B8689) |\n",
    "| **ðŸ“Š Agentic RAG with LangChain** | Step-by-Step Guide to RAG with LangChain v1, LangGraph, and Ollama (Qwen3, Gemma3, DeepSeek-R1, LLAMA, FAISS) | [Enroll Now](https://www.udemy.com/course/agentic-rag-with-langchain-and-langgraph/?referralCode=C0BCC208F53AF2C98AC5) |\n",
    "| **ðŸ”§ Master LangGraph and LangChain** | Agentic RAG and Chatbot, AI Agent with LangChain v1, Qwen3, Gemma3, DeepSeek-R1, LLAMA 3.2, FAISS Vector Database | [Enroll Now](https://www.udemy.com/course/langgraph-with-ollama/?referralCode=B646DCB44A189BEBC20C) |\n",
    "| **âš¡ Master Langchain and Ollama** | Master Langchain v1, Local LLM Projects with Ollama, Qwen3, Gemma3, DeepSeek-R1, LLAMA 3.2, Complete Integration Guide | [Enroll Now](https://www.udemy.com/course/ollama-and-langchain/?referralCode=7F4C0C7B8CF223BA9327) |\n",
    "| **ðŸ”¬ Fine Tuning LLM** | Learn transformer architecture fundamentals and fine-tune LLMs with custom datasets | [Enroll Now](https://www.udemy.com/course/fine-tuning-llm-with-hugging-face-transformers/?referralCode=6DEB3BE17C2644422D8E) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Announcement-on-ML\n",
    "<a href='http://www.kgptalkie.com' target=\"_blank\"> <img src='https://github.com/laxmimerit/Important-Announcement-on-ML/raw/master/kgptalkie_strips.png'/></a>\n",
    "\n",
    "# ML Resources\n",
    "|  ML Course | Description |\n",
    "|:---|:---|\n",
    "| [**Deploy LLM App with Ollama and Langchain in Production**](https://www.udemy.com/course/ollama-and-langchain/?referralCode=7F4C0C7B8CF223BA9327) | Master Langchain v0.3, Private Chatbot, Deploy LLM App.  Ollama, LLAMA, LLAMA 3.2, FAISS, RAG, Deploy RAG, Gen AI, LLM|\n",
    "| [**Fine Tuning LLM with HuggingFace Transformers for NLP**](https://www.udemy.com/course/fine-tuning-llm-with-hugging-face-transformers/?referralCode=6DEB3BE17C2644422D8E) | Learn how to fine tune LLM with custom dataset. You will learn basics of transformers then fine tune LLM|\n",
    "| [**Data Visualization in Python Masterclassâ„¢: Beginners to Pro**](https://bit.ly/udemy95off_kgptalkie) |  Learn to build Machine Learning and Deep Learning models using Python and its libraries like Scikit-Learn, Keras, and TensorFlow. |\n",
    "| [**Python for Machine Learning: A Step-by-Step Guide**](https://bit.ly/ml-ds-project) | Learn to build Machine Learning and Deep Learning models using Python and its libraries like Scikit-Learn, Keras, and TensorFlow. |\n",
    "| [**Deep Learning for Beginners with Python**](https://bit.ly/dl-with-python) | Neural Networks, TensorFlow, ANN, CNN, RNN, LSTM, Transfer Learning and Much More. |\n",
    "| [**Python for Linear Regression in Machine Learning**](https://bit.ly/regression-python) | Learn to build Linear Regression models using Python and its libraries like Scikit-Learn. |\n",
    "| [**Introduction to Spacy 3 for Natural Language Processing**](https://bit.ly/spacy-intro) | Learn to build Natural Language Processing models using Python and its libraries like Spacy. |\n",
    "| [**Advanced Machine Learning and Deep Learning Projects**](https://bit.ly/kgptalkie_ml_projects) | Learn to build Advanced Machine Learning and Deep Learning models using Python and transformer models like BERT, GPT-2, and XLNet. |\n",
    "| [**Natural Language Processing in Python for Beginners**](https://bit.ly/intro_nlp) | Learn to build Natural Language Processing Projects using Spacy, NLTK, and Gensim, and transformer models like BERT, GPT-2, and XLNet. |\n",
    "| [**Deployment of Machine Learning Models in Production in Python**](https://bit.ly/bert_nlp) |  Learn to deploy Machine Learning and Deep Learning models using Python and its libraries like Flask, Streamlit, and NGINX. |\n",
    "| [**R 4.0 Programming for Data Science - Beginners to Pro**](https://bit.ly/r4-ml) | Learn to build Machine Learning and Deep Learning models using R and its libraries like caret, tidyverse, and keras. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Loaders | Docling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Markdown Extraction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/docling-project/docling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 12:28:16,260 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-10-22 12:28:16,320 - INFO - Going to convert document batch...\n",
      "2025-10-22 12:28:16,320 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 4f2edc0f7d9bb60b38ebfecf9a2609f5\n",
      "2025-10-22 12:28:16,338 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-10-22 12:28:16,345 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
      "2025-10-22 12:28:16,357 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-10-22 12:28:16,378 - INFO - Registered ocr engines: ['auto', 'easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
      "2025-10-22 12:28:17,237 - INFO - Accelerator device: 'cuda:0'\n",
      "\u001b[32m[INFO] 2025-10-22 12:28:17,247 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-22 12:28:17,264 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-22 12:28:17,265 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-22 12:28:17,334 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-22 12:28:17,336 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-22 12:28:17,336 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-22 12:28:17,362 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-22 12:28:17,370 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-22 12:28:17,372 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "2025-10-22 12:28:17,442 - INFO - Auto OCR model selected rapidocr with onnxruntime.\n",
      "2025-10-22 12:28:17,460 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-10-22 12:28:18,548 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-10-22 12:28:18,894 - INFO - Processing document Apple-10-Q-2025-Q1.pdf\n",
      "2025-10-22 12:28:34,111 - INFO - Finished converting document Apple-10-Q-2025-Q1.pdf in 17.86 sec.\n"
     ]
    }
   ],
   "source": [
    "converter = DocumentConverter()\n",
    "\n",
    "file_path = \"data/Apple-10-Q-2025-Q1.pdf\"\n",
    "file_path = Path(file_path)\n",
    "\n",
    "result = converter.convert(file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"docling\", exist_ok=True)\n",
    "\n",
    "markdown = result.document.export_to_markdown()\n",
    "with open(f\"docling/{file_path.stem}.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(markdown)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = result.document.export_to_html()\n",
    "with open(f\"docling/{file_path.stem}.html\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_save(file_path):\n",
    "    file_path = Path(file_path)\n",
    "    result = converter.convert(file_path)\n",
    "\n",
    "    markdown = result.document.export_to_markdown()\n",
    "    with open(f\"docling/{file_path.stem}.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 12:28:34,269 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-10-22 12:28:34,270 - INFO - Going to convert document batch...\n",
      "2025-10-22 12:28:34,271 - INFO - Processing document scansmpl.pdf\n",
      "2025-10-22 12:28:40,648 - INFO - Finished converting document scansmpl.pdf in 6.39 sec.\n"
     ]
    }
   ],
   "source": [
    "convert_and_save(\"data/scansmpl.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 12:28:40,656 - INFO - detected formats: [<InputFormat.DOCX: 'docx'>]\n",
      "2025-10-22 12:28:40,659 - INFO - Going to convert document batch...\n",
      "2025-10-22 12:28:40,659 - INFO - Initializing pipeline for SimplePipeline with options hash 995a146ad601044538e6a923bea22f4e\n",
      "2025-10-22 12:28:40,660 - INFO - Processing document job_description.docx\n",
      "2025-10-22 12:28:40,680 - INFO - Finished converting document job_description.docx in 0.03 sec.\n"
     ]
    }
   ],
   "source": [
    "convert_and_save(\"data/job_description.docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 12:28:40,689 - INFO - detected formats: [<InputFormat.XLSX: 'xlsx'>]\n",
      "2025-10-22 12:28:40,694 - INFO - Going to convert document batch...\n",
      "2025-10-22 12:28:40,695 - INFO - Processing document sample.xlsx\n",
      "2025-10-22 12:28:40,695 - INFO - Processing sheet 0: Data\n",
      "2025-10-22 12:28:40,696 - INFO - Finished converting document sample.xlsx in 0.00 sec.\n"
     ]
    }
   ],
   "source": [
    "convert_and_save(\"data/sample.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 12:28:40,713 - INFO - detected formats: [<InputFormat.IMAGE: 'image'>]\n",
      "2025-10-22 12:28:40,883 - INFO - Going to convert document batch...\n",
      "2025-10-22 12:28:40,884 - INFO - Processing document finance and health rag system.jpg\n",
      "2025-10-22 12:28:43,276 - INFO - Finished converting document finance and health rag system.jpg in 2.58 sec.\n"
     ]
    }
   ],
   "source": [
    "convert_and_save(\"data/finance and health rag system.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"docling/tables\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 12:28:43,314 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-10-22 12:28:43,322 - INFO - Going to convert document batch...\n",
      "2025-10-22 12:28:43,322 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 4f2edc0f7d9bb60b38ebfecf9a2609f5\n",
      "2025-10-22 12:28:43,323 - INFO - Accelerator device: 'cuda:0'\n",
      "\u001b[32m[INFO] 2025-10-22 12:28:43,332 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-22 12:28:43,335 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-22 12:28:43,335 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-22 12:28:43,381 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-22 12:28:43,382 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-22 12:28:43,383 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-22 12:28:43,406 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-22 12:28:43,411 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-22 12:28:43,412 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "2025-10-22 12:28:43,477 - INFO - Auto OCR model selected rapidocr with onnxruntime.\n",
      "2025-10-22 12:28:43,478 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-10-22 12:28:44,243 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-10-22 12:28:44,499 - INFO - Processing document Apple-10-Q-2025-Q1.pdf\n",
      "2025-10-22 12:28:59,062 - INFO - Finished converting document Apple-10-Q-2025-Q1.pdf in 15.73 sec.\n"
     ]
    }
   ],
   "source": [
    "converter = DocumentConverter()\n",
    "\n",
    "file_path = \"data/Apple-10-Q-2025-Q1.pdf\"\n",
    "file_path = Path(file_path)\n",
    "\n",
    "result = converter.convert(file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 12:28:59,071 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-22 12:28:59,079 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-22 12:28:59,080 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-22 12:28:59,081 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-22 12:28:59,082 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-22 12:28:59,085 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-22 12:28:59,086 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-22 12:28:59,088 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-22 12:28:59,089 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-22 12:28:59,090 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-22 12:28:59,091 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-22 12:28:59,094 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-22 12:28:59,095 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-22 12:28:59,096 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-22 12:28:59,097 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-22 12:28:59,098 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-22 12:28:59,099 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-22 12:28:59,100 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-22 12:28:59,100 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-22 12:28:59,102 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-22 12:28:59,102 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-22 12:28:59,104 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-22 12:28:59,105 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-22 12:28:59,106 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n",
      "2025-10-22 12:28:59,107 - WARNING - Usage of TableItem.export_to_dataframe() without `doc` argument is deprecated.\n"
     ]
    }
   ],
   "source": [
    "for i, table in enumerate(result.document.tables):\n",
    "    df = table.export_to_dataframe()\n",
    "\n",
    "    df.to_csv(f\"docling/tables/{file_path.stem}_table_{i+1}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Figures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.document_converter import PdfFormatOption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"docling/figures\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_options = PdfPipelineOptions()\n",
    "pipeline_options.generate_picture_images = True\n",
    "pipeline_options.images_scale = 3.0\n",
    "\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(\n",
    "            pipeline_options=pipeline_options\n",
    "            )})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 12:28:59,161 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-10-22 12:28:59,163 - INFO - Going to convert document batch...\n",
      "2025-10-22 12:28:59,163 - INFO - Initializing pipeline for StandardPdfPipeline with options hash e13f1ccd8170a627ad25ebdda600bbe2\n",
      "2025-10-22 12:28:59,164 - INFO - Accelerator device: 'cuda:0'\n",
      "\u001b[32m[INFO] 2025-10-22 12:28:59,174 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-22 12:28:59,177 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-22 12:28:59,178 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_det_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-22 12:28:59,218 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-22 12:28:59,220 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-22 12:28:59,220 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_ppocr_mobile_v2.0_cls_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-22 12:28:59,244 [RapidOCR] base.py:22: Using engine_name: onnxruntime\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-22 12:28:59,249 [RapidOCR] download_file.py:60: File exists and is valid: C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "\u001b[32m[INFO] 2025-10-22 12:28:59,250 [RapidOCR] main.py:53: Using C:\\Users\\laxmi\\anaconda3\\envs\\ml\\Lib\\site-packages\\rapidocr\\models\\ch_PP-OCRv4_rec_infer.onnx\u001b[0m\n",
      "2025-10-22 12:28:59,317 - INFO - Auto OCR model selected rapidocr with onnxruntime.\n",
      "2025-10-22 12:28:59,318 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-10-22 12:29:00,110 - INFO - Accelerator device: 'cuda:0'\n",
      "2025-10-22 12:29:00,428 - INFO - Processing document sample_textbook.pdf\n",
      "2025-10-22 12:29:03,032 - INFO - Finished converting document sample_textbook.pdf in 3.88 sec.\n"
     ]
    }
   ],
   "source": [
    "file_path = \"data/sample_textbook.pdf\"\n",
    "file_path = Path(file_path)\n",
    "\n",
    "result = converter.convert(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, picture in enumerate(result.document.pictures):\n",
    "    image = picture.get_image(result.document)\n",
    "\n",
    "    image.save(f\"docling/figures/{file_path.stem}_figure_{i+1}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
