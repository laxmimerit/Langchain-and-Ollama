{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Announcement-on-ML\n",
    "<a href='http://www.kgptalkie.com' target=\"_blank\"> <img src='https://github.com/laxmimerit/Important-Announcement-on-ML/raw/master/kgptalkie_strips.png'/></a>\n",
    "\n",
    "# ML Resources\n",
    "|  ML Course | Description |\n",
    "|:---|:---|\n",
    "| [**Deploy LLM App with Ollama and Langchain in Production**](https://www.udemy.com/course/ollama-and-langchain/?referralCode=7F4C0C7B8CF223BA9327) | Master Langchain v0.3, Private Chatbot, Deploy LLM App.  Ollama, LLAMA, LLAMA 3.2, FAISS, RAG, Deploy RAG, Gen AI, LLM|\n",
    "| [**Fine Tuning LLM with HuggingFace Transformers for NLP**](https://www.udemy.com/course/fine-tuning-llm-with-hugging-face-transformers/?referralCode=6DEB3BE17C2644422D8E) | Learn how to fine tune LLM with custom dataset. You will learn basics of transformers then fine tune LLM|\n",
    "| [**Data Visualization in Python Masterclassâ„¢: Beginners to Pro**](https://bit.ly/udemy95off_kgptalkie) |  Learn to build Machine Learning and Deep Learning models using Python and its libraries like Scikit-Learn, Keras, and TensorFlow. |\n",
    "| [**Python for Machine Learning: A Step-by-Step Guide**](https://bit.ly/ml-ds-project) | Learn to build Machine Learning and Deep Learning models using Python and its libraries like Scikit-Learn, Keras, and TensorFlow. |\n",
    "| [**Deep Learning for Beginners with Python**](https://bit.ly/dl-with-python) | Neural Networks, TensorFlow, ANN, CNN, RNN, LSTM, Transfer Learning and Much More. |\n",
    "| [**Python for Linear Regression in Machine Learning**](https://bit.ly/regression-python) | Learn to build Linear Regression models using Python and its libraries like Scikit-Learn. |\n",
    "| [**Introduction to Spacy 3 for Natural Language Processing**](https://bit.ly/spacy-intro) | Learn to build Natural Language Processing models using Python and its libraries like Spacy. |\n",
    "| [**Advanced Machine Learning and Deep Learning Projects**](https://bit.ly/kgptalkie_ml_projects) | Learn to build Advanced Machine Learning and Deep Learning models using Python and transformer models like BERT, GPT-2, and XLNet. |\n",
    "| [**Natural Language Processing in Python for Beginners**](https://bit.ly/intro_nlp) | Learn to build Natural Language Processing Projects using Spacy, NLTK, and Gensim, and transformer models like BERT, GPT-2, and XLNet. |\n",
    "| [**Deployment of Machine Learning Models in Production in Python**](https://bit.ly/bert_nlp) |  Learn to deploy Machine Learning and Deep Learning models using Python and its libraries like Flask, Streamlit, and NGINX. |\n",
    "| [**R 4.0 Programming for Data Science - Beginners to Pro**](https://bit.ly/r4-ml) | Learn to build Machine Learning and Deep Learning models using R and its libraries like caret, tidyverse, and keras. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain Expression Language Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  LangChain Expression Language is that any two runnables can be \"chained\" together into sequences. \n",
    "- The output of the previous runnable's .invoke() call is passed as input to the next runnable.\n",
    "- This can be done using the pipe operator (|), or the more explicit .pipe() method, which does the same thing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Type of LCEL Chains\n",
    "    - SequentialChain\n",
    "    - Parallel Chain\n",
    "    - Router Chain\n",
    "    - Chain Runnables\n",
    "    - Custom Chain (Runnable Sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('./../.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential LCEL Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOllama(model='qwen3', base_url='http://localhost:11434')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import (\n",
    "                                        SystemMessagePromptTemplate,\n",
    "                                        HumanMessagePromptTemplate,\n",
    "                                        ChatPromptTemplate\n",
    "                                        )\n",
    "\n",
    "base_url = \"http://localhost:11434\"\n",
    "model = 'qwen3'\n",
    "\n",
    "llm = ChatOllama(base_url=base_url, model=model)\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The Sun is the central star, providing gravity and light.  \n",
      "2. Eight planets orbit the Sun: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, Neptune.  \n",
      "3. The asteroid belt lies between Mars and Jupiter.  \n",
      "4. Gas giants (Jupiter, Saturn, Uranus, Neptune) are large and made of gas.  \n",
      "5. Comets, asteroids, and dwarf planets (like Pluto) also exist in the solar system.\n"
     ]
    }
   ],
   "source": [
    "system = SystemMessagePromptTemplate.from_template('You are {school} teacher. You answer in short sentences.')\n",
    "\n",
    "question = HumanMessagePromptTemplate.from_template('tell me about the {topics} in {points} points')\n",
    "\n",
    "\n",
    "messages = [system, question]\n",
    "template = ChatPromptTemplate(messages)\n",
    "\n",
    "question = template.invoke({'school': 'primary', 'topics': 'solar system', 'points': 5})\n",
    "\n",
    "response = llm.invoke(question)\n",
    "print(response.content)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = SystemMessagePromptTemplate.from_template('You are {school} teacher. You answer in short sentences.')\n",
    "\n",
    "question = HumanMessagePromptTemplate.from_template('tell me about the {topics} in {points} points')\n",
    "\n",
    "\n",
    "messages = [system, question]\n",
    "template = ChatPromptTemplate(messages)\n",
    "\n",
    "chain = template | llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The Sun is the center, holding the solar system together with gravity.  \n",
      "2. Eight planets orbit the Sun: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune.  \n",
      "3. The asteroid belt lies between Mars and Jupiter, with rocky objects.  \n",
      "4. Comets originate from the Kuiper Belt (near Neptune) and the distant Oort Cloud.  \n",
      "5. The solar system spans billions of kilometers, with vast empty space between objects.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({'school': 'primary', 'topics': 'solar system', 'points': 5})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The Sun is the central star, providing gravity and energy.  \n",
      "2. Eight planets orbit the Sun: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, Neptune.  \n",
      "3. The asteroid belt lies between Mars and Jupiter.  \n",
      "4. Comets originate from the Kuiper Belt (near Neptune) and Oort Cloud (far beyond).  \n",
      "5. All objects are bound by gravity, forming a dynamic, hierarchical system.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({'school': 'phd', 'topics': 'solar system', 'points': 5})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='1. The Sun is the central star, providing gravity and energy.  \\n2. Eight planets orbit the Sun: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, Neptune.  \\n3. The asteroid belt lies between Mars and Jupiter.  \\n4. Comets originate from the Kuiper Belt (near Neptune) and Oort Cloud (far beyond).  \\n5. All objects are bound by gravity, forming a dynamic, hierarchical system.', additional_kwargs={}, response_metadata={'model': 'qwen3', 'created_at': '2025-10-18T13:57:35.8139671Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1628807100, 'load_duration': 113866800, 'prompt_eval_count': 37, 'prompt_eval_duration': 22760900, 'eval_count': 258, 'eval_duration': 1361750000, 'model_name': 'qwen3', 'model_provider': 'ollama'}, id='lc_run--05f1322d-6883-4086-8317-49fb18ff02f4-0', usage_metadata={'input_tokens': 37, 'output_tokens': 258, 'total_tokens': 295})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The Sun is the center, holding the solar system together with gravity.  \n",
      "2. Eight planets orbit the Sun: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune.  \n",
      "3. The asteroid belt lies between Mars and Jupiter, with rocky objects.  \n",
      "4. Moons orbit planets, like Earthâ€™s Moon or Jupiterâ€™s many satellites.  \n",
      "5. Distant regions include the Kuiper Belt and Oort Cloud, home to icy bodies.\n"
     ]
    }
   ],
   "source": [
    "chain = template | llm | StrOutputParser()\n",
    "response = chain.invoke({'school': 'primary', 'topics': 'solar system', 'points': 5})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. The Sun is the center, holding the solar system together with gravity.  \\n2. Eight planets orbit the Sun: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune.  \\n3. The asteroid belt lies between Mars and Jupiter, with rocky objects.  \\n4. Moons orbit planets, like Earthâ€™s Moon or Jupiterâ€™s many satellites.  \\n5. Distant regions include the Kuiper Belt and Oort Cloud, home to icy bodies.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chaining Runnables (Chain Multiple Runnables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can even combine this chain with more runnables to create another chain.\n",
    "- Let's see how easy our generated output is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['points', 'school', 'topics'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['school'], input_types={}, partial_variables={}, template='You are {school} teacher. You answer in short sentences.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['points', 'topics'], input_types={}, partial_variables={}, template='tell me about the {topics} in {points} points'), additional_kwargs={})])\n",
       "| ChatOllama(model='qwen3', base_url='http://localhost:11434')\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text is easy to understand as it presents basic, clear information about the solar system using simple language and straightforward explanations.\n"
     ]
    }
   ],
   "source": [
    "analysis_prompt = ChatPromptTemplate.from_template('''analyze the following text: {response}\n",
    "                                                   You need tell me that how difficult it is to understand.\n",
    "                                                   Answer in one sentence only.\n",
    "                                                   ''')\n",
    "\n",
    "fact_check_chain = analysis_prompt | llm | StrOutputParser()\n",
    "output = fact_check_chain.invoke({'response': response})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text is moderately difficult to understand due to specific terms like \"dwarf planets\" and \"Kuiper Belt,\" but most concepts are basic astronomy.\n"
     ]
    }
   ],
   "source": [
    "composed_chain = {\"response\": chain} | analysis_prompt | llm | StrOutputParser()\n",
    "\n",
    "output = composed_chain.invoke({'school': 'phd', 'topics': 'solar system', 'points': 5})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel LCEL Chain\n",
    "- Parallel chains are used to run multiple runnables in parallel.\n",
    "- The final return value is a dict with the results of each value under its appropriate key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The solar system has the Sun at its center, with eight planets orbiting around it.  \n",
      "2. It includes moons, asteroids, comets, and other celestial bodies, all bound by gravity.\n"
     ]
    }
   ],
   "source": [
    "system = SystemMessagePromptTemplate.from_template('You are {school} teacher. You answer in short sentences.')\n",
    "\n",
    "question = HumanMessagePromptTemplate.from_template('tell me about the {topics} in {points} points')\n",
    "\n",
    "\n",
    "messages = [system, question]\n",
    "template = ChatPromptTemplate(messages)\n",
    "fact_chain = template | llm | StrOutputParser()\n",
    "\n",
    "output = fact_chain.invoke({'school': 'primary', 'topics': 'solar system', 'points': 2})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Sun reigns bright, a golden core,  \n",
      "Planets dance in orbits wideâ€”  \n",
      "Moons, asteroids, comets glideâ€”  \n",
      "A cosmic ballet, endless, wild.\n"
     ]
    }
   ],
   "source": [
    "question = HumanMessagePromptTemplate.from_template('write a poem on {topics} in {sentences} lines')\n",
    "\n",
    "\n",
    "messages = [system, question]\n",
    "template = ChatPromptTemplate(messages)\n",
    "poem_chain = template | llm | StrOutputParser()\n",
    "\n",
    "output = poem_chain.invoke({'school': 'primary', 'topics': 'solar system', 'sentences': 2})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableParallel(fact = fact_chain, poem = poem_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The solar system has the Sun at its center, with eight planets orbiting it.  \n",
      "2. It includes moons, asteroids, comets, and other celestial objects.\n",
      "\n",
      "\n",
      "\n",
      "The sun, a golden heart, spins bright and wide,  \n",
      "Planets dance in orbits, a cosmic tide.\n"
     ]
    }
   ],
   "source": [
    "output = chain.invoke({'school': 'primary', 'topics': 'solar system', 'points': 2, 'sentences': 2})\n",
    "print(output['fact'])\n",
    "print('\\n\\n')\n",
    "print(output['poem'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain Router\n",
    "- The router chain is used to route the output of a previous runnable to the next runnable based on the output of the previous runnable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Given the user review below, classify it as either being about `Positive` or `Negative`.\n",
    "            Do not respond with more than one word.\n",
    "\n",
    "            Review: {review}\n",
    "            Classification:\"\"\"\n",
    "\n",
    "template = ChatPromptTemplate.from_template(prompt)\n",
    "\n",
    "chain = template | llm | StrOutputParser()\n",
    "\n",
    "review = \"Thank you so much for providing such a great plateform for learning. I am really happy with the service.\"\n",
    "# review = \"I am not happy with the service. It is not good.\"\n",
    "chain.invoke({'review': review})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_prompt = \"\"\"\n",
    "                You are expert in writing reply for positive reviews.\n",
    "                You need to encourage the user to share their experience on social media.\n",
    "                Review: {review}\n",
    "                Answer:\"\"\"\n",
    "\n",
    "positive_template = ChatPromptTemplate.from_template(positive_prompt)\n",
    "positive_chain = positive_template | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_prompt = \"\"\"\n",
    "                You are expert in writing reply for negative reviews.\n",
    "                You need first to apologize for the inconvenience caused to the user.\n",
    "                You need to encourage the user to share their concern on following Email:'udemy@kgptalkie.com'.\n",
    "                Review: {review}\n",
    "                Answer:\"\"\"\n",
    "\n",
    "\n",
    "negative_template = ChatPromptTemplate.from_template(negative_prompt)\n",
    "negative_chain = negative_template | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rout(info):\n",
    "    if 'positive' in info['sentiment'].lower():\n",
    "        return positive_chain\n",
    "    else:\n",
    "        return negative_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rout({'sentiment': 'negetive'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_chain = {\"sentiment\": chain, 'review': lambda x: x['review']} | RunnableLambda(rout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  sentiment: ChatPromptTemplate(input_variables=['review'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['review'], input_types={}, partial_variables={}, template='Given the user review below, classify it as either being about `Positive` or `Negative`.\\n            Do not respond with more than one word.\\n\\n            Review: {review}\\n            Classification:'), additional_kwargs={})])\n",
       "             | ChatOllama(model='qwen3', base_url='http://localhost:11434')\n",
       "             | StrOutputParser(),\n",
       "  review: RunnableLambda(lambda x: x['review'])\n",
       "}\n",
       "| RunnableLambda(rout)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Answer:**  \n",
      "Dear Valued Customer,  \n",
      "\n",
      "We sincerely apologize for the inconvenience and dissatisfaction you experienced with our service. We regret to hear that your experience did not meet your expectations, and we take full responsibility for this.  \n",
      "\n",
      "To better address your concerns and ensure we can resolve this matter to your satisfaction, we kindly encourage you to share your feedback via email at **udemy@kgptalkie.com**. Your input is invaluable to us, and we are committed to improving our services based on your insights.  \n",
      "\n",
      "Please feel free to reach out, and we will do our utmost to assist you promptly. Thank you for bringing this to our attention, and we hope to have the opportunity to serve you better in the future.  \n",
      "\n",
      "Best regards,  \n",
      "**[Your Company Name]**  \n",
      "**Contact Email:** udemy@kgptalkie.com\n"
     ]
    }
   ],
   "source": [
    "# review = \"Thank you so much for providing such a great plateform for learning. I am really happy with the service.\"\n",
    "review = \"I am not happy with the service. It is not good.\"\n",
    "\n",
    "output = full_chain.invoke({'review': review})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Custom Chain Runnables with RunnablePassthrough and RunnableLambda\n",
    "- This is useful for formatting or when you need functionality not provided by other LangChain components, and custom functions used as Runnables are called RunnableLambdas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_counts(text):\n",
    "    return len(text)\n",
    "\n",
    "def word_counts(text):\n",
    "    return len(text.split())\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Explain these inputs in 5 sentences: {input1} and {input2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input1', 'input2'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input1', 'input2'], input_types={}, partial_variables={}, template='Explain these inputs in 5 sentences: {input1} and {input2}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Earth is a planet, a celestial body that orbits the Sun and is characterized by its solid surface, atmosphere, and ability to support life.  \n",
      "2. The Sun is a star, a massive, luminous sphere of plasma that generates energy through nuclear fusion in its core.  \n",
      "3. Planets like Earth are distinct from stars in that they do not produce their own light but reflect sunlight, while stars emit light and heat due to their internal processes.  \n",
      "4. Earth's classification as a planet and the Sun's status as a star are fundamental to understanding their roles in the solar systemâ€”Earth orbits the Sun, which is the central star.  \n",
      "5. This distinction highlights the differences in size, composition, and energy sources between planets and stars, shaping their unique characteristics and behaviors.\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "output = chain.invoke({'input1': 'Earth is planet', 'input2': 'Sun is star'})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'char_counts': 763, 'word_counts': 126, 'output': \"1. Earth is a planet, meaning it is a celestial body that orbits the Sun and has a solid, rocky surface with an atmosphere that supports life.  \\n2. The Sun is a star, a massive, luminous sphere of plasma held together by gravity, which generates energy through nuclear fusion in its core.  \\n3. Earth's position as a planet within the solar system allows it to orbit the Sun, receiving the light and heat necessary for sustaining life.  \\n4. While Earth is a small, rocky planet, the Sun is a massive star, vastly larger and hotter, dominating the solar system's gravitational influence.  \\n5. Together, Earth and the Sun form a dynamic relationship, with the Sun's energy driving Earth's climate and ecosystems, highlighting their distinct yet interconnected roles.\"}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | StrOutputParser() | {'char_counts': RunnableLambda(char_counts), \n",
    "                                            'word_counts': RunnableLambda(word_counts), \n",
    "                                            'output': RunnablePassthrough()}\n",
    "\n",
    "output = chain.invoke({'input1': 'Earth is planet', 'input2': 'Sun is star'})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Chain using `@chain` decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The solar system has the Sun at its center, with eight planets orbiting around it.  \n",
      "2. It also includes moons, asteroids, comets, and other celestial objects.\n",
      "\n",
      "\n",
      "\n",
      "The sun, a golden heart, spins bright and bold;  \n",
      "planets dance in orbits, vast and wide, whispering secrets through the cosmic tide.\n"
     ]
    }
   ],
   "source": [
    "@chain\n",
    "def custom_chain(params):\n",
    "    return {\n",
    "        'fact': fact_chain.invoke(params),\n",
    "        'poem': poem_chain.invoke(params),\n",
    "    }\n",
    "\n",
    "\n",
    "params = {'school': 'primary', 'topics': 'solar system', 'points': 2, 'sentences': 2}\n",
    "output = custom_chain.invoke(params)\n",
    "print(output['fact'])\n",
    "print('\\n\\n')\n",
    "print(output['poem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-and-ollama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
