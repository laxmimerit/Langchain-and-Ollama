{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c364c80",
   "metadata": {},
   "source": [
    "## Agentic RAG with Langchain v1, Ollama, and FAISS\n",
    "**Key Features:**\n",
    "- Agent-based architecture with autonomous tool usage for document retrieval\n",
    "- FAISS vector store for efficient semantic search across document embeddings\n",
    "- Ollama integration with Qwen3 LLM and nomic-embed-text embeddings for local deployment\n",
    "- Custom retrieval tool that finds and formats relevant document chunks with metadata\n",
    "- Interactive chat interface with streaming responses and tool call visibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61a582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ollama pull nomic-embed-text\n",
    "# ollama pull qwen3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750be741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the langchain pre-release for latest features\n",
    "# pip install -U langchain langchain-ollama, langchain-community langchain-core faiss-cpu\n",
    "import os\n",
    "import warnings\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ============================================================================\n",
    "# LLM & VECTOR STORE SETUP\n",
    "# ============================================================================\n",
    "# Ollama LLM with Qwen3\n",
    "llm = ChatOllama(\n",
    "    model=\"qwen3\", \n",
    "    base_url=\"http://localhost:11434\"\n",
    ")\n",
    "\n",
    "# Ollama Embeddings\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"nomic-embed-text\",\n",
    "    base_url=\"http://localhost:11434\"\n",
    ")\n",
    "\n",
    "# FAISS Vector Store (assumes data already exists from previous code)\n",
    "db_name = \"./../09. Vector Stores and Retrievals/health_supplements\"\n",
    "vector_store = FAISS.load_local(\n",
    "    db_name,\n",
    "    embeddings,\n",
    "    allow_dangerous_deserialization=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ce7c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53deb9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VECTOR STORE VERIFICATION\n",
    "# ============================================================================\n",
    "print(\"\\nüîç Testing Vector Store Connection...\")\n",
    "\n",
    "# Test 1: Check collection info\n",
    "doc_count = vector_store.index.ntotal\n",
    "print(f\"‚úì Vector store found with {doc_count} documents\")\n",
    "\n",
    "\n",
    "# Test 2: Sample similarity search\n",
    "test_query = \"creatine\"\n",
    "results = vector_store.similarity_search(test_query, k=3)\n",
    "print(f\"\\n‚úì Sample search for '{test_query}':\")\n",
    "for i, doc in enumerate(results, 1):\n",
    "    print(f\"  {i}. Page {doc.metadata.get('page', '?')}: {doc.page_content[:100]}...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c7c069",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc82f15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# RETRIEVAL TOOL\n",
    "# ============================================================================\n",
    "@tool()\n",
    "def retrieve_context(query: str):\n",
    "    \"\"\"Retrieve relevant information for health related queries from the document to answer the query.\n",
    "    \n",
    "    \"\"\"\n",
    "    print(f\"üîç Searching: '{query}'\")\n",
    "    \n",
    "    # Perform similarity search\n",
    "    docs = vector_store.similarity_search(query, k=4)\n",
    "    \n",
    "    # Format for LLM\n",
    "    content = \"\\n\\n\".join(\n",
    "        f\"Page {doc.metadata.get('page', '?')}: {doc.page_content}\" \n",
    "        for doc in docs\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úì Found {len(docs)} relevant chunks\")\n",
    "    return content, docs\n",
    "\n",
    "# ============================================================================\n",
    "# AGENT CREATION\n",
    "# ============================================================================\n",
    "tools = [retrieve_context]\n",
    "\n",
    "# Agent prompt - simplified for single tool\n",
    "system_prompt = \"\"\"You are a research assistant with a document retrieval tool.\n",
    "\n",
    "                    Tool:\n",
    "                    - retrieve_context: Search the document for relevant information\n",
    "\n",
    "                    Always use the tool to find relevant information before answering.\n",
    "                    Cite page numbers and be thorough.\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717c7717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the agentic RAG\n",
    "rag_agent = create_agent(llm, tools, system_prompt=system_prompt)\n",
    "\n",
    "rag_agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4810cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_agent\n",
    "\n",
    "response = rag_agent.invoke({'messages': \"What is the use of BCAA?\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f3bcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# QUERY FUNCTION\n",
    "# ============================================================================\n",
    "def ask(question: str):\n",
    "    \"\"\"Ask the agentic RAG a question.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Question: {question}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    for event in rag_agent.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": question}]},\n",
    "        stream_mode=\"values\"\n",
    "    ):\n",
    "        msg = event[\"messages\"][-1]\n",
    "        \n",
    "        # Show tool usage\n",
    "        if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "            for tc in msg.tool_calls:\n",
    "                print(f\"\\nüîß Using: {tc['name']} with {tc['args']}\")\n",
    "        \n",
    "        # Show final answer\n",
    "        elif hasattr(msg, 'content') and msg.content:\n",
    "            print(f\"\\nüí¨ Answer:\\n{msg.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed913f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TESTING\n",
    "# ============================================================================\n",
    "# Test basic retrieval\n",
    "ask(\"how to gain muscle mass?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a082a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# INTERACTIVE CHAT\n",
    "# ============================================================================\n",
    "def chat():\n",
    "    \"\"\"Start interactive chat with the agentic RAG.\"\"\"\n",
    "    print(\"\\nü§ñ Agentic RAG Chat - Type 'quit, q or exit' to exit\")\n",
    "    \n",
    "    while True:\n",
    "        question = input(\"\\nYour question: \").strip()\n",
    "        if question.lower() in ['quit', 'exit', 'q']:\n",
    "            break\n",
    "        if question:\n",
    "            ask(question)\n",
    "\n",
    "chat()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
