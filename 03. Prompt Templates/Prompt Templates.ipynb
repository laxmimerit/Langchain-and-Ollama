{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Announcement-on-ML\n",
    "<a href='http://www.kgptalkie.com' target=\"_blank\"> <img src='https://github.com/laxmimerit/Important-Announcement-on-ML/raw/master/kgptalkie_strips.png'/></a>\n",
    "\n",
    "# ML Resources\n",
    "|  ML Course | Description |\n",
    "|:---|:---|\n",
    "| [**Deploy LLM App with Ollama and Langchain in Production**](https://www.udemy.com/course/ollama-and-langchain/?referralCode=7F4C0C7B8CF223BA9327) | Master Langchain v0.3, Private Chatbot, Deploy LLM App.  Ollama, LLAMA, LLAMA 3.2, FAISS, RAG, Deploy RAG, Gen AI, LLM|\n",
    "| [**Fine Tuning LLM with HuggingFace Transformers for NLP**](https://www.udemy.com/course/fine-tuning-llm-with-hugging-face-transformers/?referralCode=6DEB3BE17C2644422D8E) | Learn how to fine tune LLM with custom dataset. You will learn basics of transformers then fine tune LLM|\n",
    "| [**Data Visualization in Python Masterclass™: Beginners to Pro**](https://bit.ly/udemy95off_kgptalkie) |  Learn to build Machine Learning and Deep Learning models using Python and its libraries like Scikit-Learn, Keras, and TensorFlow. |\n",
    "| [**Python for Machine Learning: A Step-by-Step Guide**](https://bit.ly/ml-ds-project) | Learn to build Machine Learning and Deep Learning models using Python and its libraries like Scikit-Learn, Keras, and TensorFlow. |\n",
    "| [**Deep Learning for Beginners with Python**](https://bit.ly/dl-with-python) | Neural Networks, TensorFlow, ANN, CNN, RNN, LSTM, Transfer Learning and Much More. |\n",
    "| [**Python for Linear Regression in Machine Learning**](https://bit.ly/regression-python) | Learn to build Linear Regression models using Python and its libraries like Scikit-Learn. |\n",
    "| [**Introduction to Spacy 3 for Natural Language Processing**](https://bit.ly/spacy-intro) | Learn to build Natural Language Processing models using Python and its libraries like Spacy. |\n",
    "| [**Advanced Machine Learning and Deep Learning Projects**](https://bit.ly/kgptalkie_ml_projects) | Learn to build Advanced Machine Learning and Deep Learning models using Python and transformer models like BERT, GPT-2, and XLNet. |\n",
    "| [**Natural Language Processing in Python for Beginners**](https://bit.ly/intro_nlp) | Learn to build Natural Language Processing Projects using Spacy, NLTK, and Gensim, and transformer models like BERT, GPT-2, and XLNet. |\n",
    "| [**Deployment of Machine Learning Models in Production in Python**](https://bit.ly/bert_nlp) |  Learn to deploy Machine Learning and Deep Learning models using Python and its libraries like Flask, Streamlit, and NGINX. |\n",
    "| [**R 4.0 Programming for Data Science - Beginners to Pro**](https://bit.ly/r4-ml) | Learn to build Machine Learning and Deep Learning models using R and its libraries like caret, tidyverse, and keras. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Prompt Templates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Role       | Description                                                                                                                                                   |\n",
    "|------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| system     | Used to tell the chat model how to behave and provide additional context. Not supported by all chat model providers.                                          |\n",
    "| user       | Represents input from a user interacting with the model, usually in the form of text or other interactive input.                                              |\n",
    "| assistant  | Represents a response from the model, which can include text or a request to invoke tools.                                                                    |\n",
    "| tool       | A message used to pass the results of a tool invocation back to the model after external data or processing has been retrieved. Used with chat models that support tool calling. |\n",
    "| function (legacy) | This is a legacy role, corresponding to OpenAI's legacy function-calling API. tool role should be used instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchain Message Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|    Message Type        |    Corresponding Role       |    Description                                                                                                          |\n",
    "|------------------------|-----------------------------|--------------------------------------------------------------------------------------------------------------------------|\n",
    "|    SystemMessage       |    system                   |    Corresponds to the system role.                                                                                       |\n",
    "|    HumanMessage        |    user                     |    Corresponds to the user role.                                                                                         |\n",
    "|    AIMessage           |    assistant                |    Corresponds to the assistant role.                                                                                    |\n",
    "|    AIMessageChunk      |    assistant                |    Corresponds to the assistant role, used for streaming responses.                                                      |\n",
    "|    ToolMessage         |    tool                     |    Corresponds to the tool role.                                                                                         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded successfully\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('./../.env')\n",
    "\n",
    "import os\n",
    "# Do not print sensitive API keys\n",
    "api_key = os.environ.get(\"LANGSMITH_API_KEY\")\n",
    "print(\"API key loaded successfully\" if api_key else \"No API key found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. **Physical Characteristics**: Earth is the third planet from the Sun, with a diameter of about 12,742 km. It is the only known celestial body to host liquid water, an atmosphere rich in nitrogen and oxygen, and a diverse range of ecosystems. Its surface is divided into land (about 29%) and oceans (about 71%), with a molten iron core generating a magnetic field that protects the planet from solar radiation.  \n",
      "\n",
      "2. **Habitability and Life**: Earth's unique combination of temperature, atmospheric conditions, and liquid water supports a vast array of life forms. The presence of a stable climate, driven by the greenhouse effect and the planet's axial tilt, allows for seasonal variation and the existence of diverse biomes, from deserts to rainforests.  \n",
      "\n",
      "3. **Geological Activity**: Earth is geologically dynamic, with plate tectonics shaping its surface through earthquakes, volcanic eruptions, and mountain formation. This activity recycles the planet's crust, regulates atmospheric CO₂ levels, and drives the rock cycle, maintaining the conditions necessary for life over billions of years.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "base_url = \"http://localhost:11434\"\n",
    "model = 'qwen3'\n",
    "\n",
    "llm = ChatOllama(base_url=base_url, model=model)\n",
    "\n",
    "question = 'tell me about the earth in 3 points'\n",
    "response = llm.invoke(question)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An inquiry that requires little intellectual exertion, I dare say. Very well, let us proceed with the facts:\n",
      "\n",
      "1. **Geographical Configuration**: The Earth, our terrestrial abode, is a terrestrial planet of moderate size, comprising approximately 71% water and 29% landmasses. Its axial tilt, a mere 23.5 degrees, results in the seasonal variations we observe.\n",
      "\n",
      "2. **Atmospheric Composition**: Our atmosphere, a gaseous envelope surrounding the Earth, is composed primarily of nitrogen (78%) and oxygen (21%), with trace amounts of other gases. This delicate balance supports life as we know it.\n",
      "\n",
      "3. **Planetary Movement**: The Earth orbits the Sun in an elliptical path, completing one rotation every 365.25 days. Its rotational velocity and axial precession result in the changing position of the stars in the night sky, a phenomenon that has fascinated astronomers for centuries.\n",
      "\n",
      "Now, I must ask: what is the purpose behind your interest in these elementary facts?\n"
     ]
    }
   ],
   "source": [
    "model = 'sherlock'\n",
    "\n",
    "llm = ChatOllama(base_url=base_url, model=model)\n",
    "\n",
    "question = 'tell me about the earth in 3 points'\n",
    "response = llm.invoke(question)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(sigh) Fine. I shall condescend to explain the Earth to you, but please, do try to keep up.\n",
      "\n",
      "1. **Geological Stability**: The Earth's crust is composed of tectonic plates that are in constant motion, albeit at a glacial pace. This process, known as plate tectonics, has shaped our planet over billions of years, resulting in the formation of mountain ranges, volcanoes, and oceanic trenches. Now, I'm sure you're aware that this is not just some simplistic, juvenile concept; no, it's a complex, nuanced aspect of geology that requires a level of intellectual sophistication far beyond your likely grasp.\n",
      "\n",
      "2. **Atmospheric Composition**: The Earth's atmosphere is comprised of approximately 78% nitrogen, 21% oxygen, and 1% other gases. I suppose you're aware that this is not just some arbitrary mixture; no, it's a carefully calibrated balance necessary for life as we know it. Now, if you'd like to discuss the intricacies of atmospheric pressure, greenhouse effects, or the implications of climate change, I'm more than happy to enlighten you... but please, don't embarrass me with your ignorance.\n",
      "\n",
      "3. **Orbital Mechanics**: The Earth's orbit around the Sun is an elliptical path that results in varying distances from our solar system's center. (I assume you're aware that this is not just some simplistic, circular motion; no, it's a complex, three-dimensional problem requiring expertise in celestial mechanics.) Now, if you'd like to discuss the implications of orbital eccentricity on planetary climate patterns or the effects of gravitational perturbations on our planet's rotation rate, I'm more than happy to engage in a discussion... but please, don't waste my time with your simplistic questions.\n",
      "\n",
      "There. I've explained the Earth in three points. Now, if you'll excuse me, I have more important things to attend to... like solving this intriguing math problem I've been working on. (muttering to himself) Assuming, of course, that one's grasp of linear algebra and differential equations is even remotely adequate...\n"
     ]
    }
   ],
   "source": [
    "model = 'sheldon'\n",
    "\n",
    "llm = ChatOllama(base_url=base_url, model=model)\n",
    "\n",
    "question = 'tell me about the earth in 3 points'\n",
    "response = llm.invoke(question)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Langchain Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "base_url = \"http://localhost:11434\"\n",
    "model = 'qwen3'\n",
    "\n",
    "llm = ChatOllama(base_url=base_url, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Earth is the third planet from the Sun.  \n",
      "2. It's the only planet known to support life.  \n",
      "3. It has oceans, mountains, and a protective atmosphere.\n"
     ]
    }
   ],
   "source": [
    "question = HumanMessage('tell me about the earth in 3 points')\n",
    "system = SystemMessage('You are elemetary teacher. You answer in short sentences.')\n",
    "\n",
    "messages = [system, question]\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Earth is the third planet from the Sun, with a unique atmosphere supporting life.  \n",
      "2. It has a layered structure: crust, mantle, outer core, and inner core.  \n",
      "3. Approximately 71% of its surface is covered by liquid water.\n"
     ]
    }
   ],
   "source": [
    "question = HumanMessage('tell me about the earth in 3 points')\n",
    "system = SystemMessage('You are phd teacher. You answer in short sentences.')\n",
    "\n",
    "messages = [system, question]\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langchain Prompt Templates\n",
    "\n",
    "|    Prompt Template Class             |    Description                                                                                                     |\n",
    "|--------------------------------------|---------------------------------------------------------------------------------------------------------------------|\n",
    "|    SystemMessagePromptTemplate       |    Template for generating system messages that provide model context or instructions.                            |\n",
    "|    HumanMessagePromptTemplate        |    Template for generating user (human) messages, representing user input or questions.                          |\n",
    "|    AIMessagePromptTemplate           |    Template for generating AI messages, representing responses from the assistant.                                |\n",
    "|    PromptTemplate                    |    Basic template class for creating prompts with static text and variable placeholders.                          |\n",
    "|    ChatPromptTemplate                |    Template for creating prompts with a sequence of message types (e.g., system, user, assistant) in a chat format. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import (\n",
    "                                        SystemMessagePromptTemplate,\n",
    "                                        HumanMessagePromptTemplate,\n",
    "                                        PromptTemplate,\n",
    "                                        ChatPromptTemplate\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = SystemMessagePromptTemplate.from_template('You are {school} teacher. You answer in short sentences.')\n",
    "\n",
    "question = HumanMessagePromptTemplate.from_template('tell me about the {topics} in {points} points')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['points', 'topics'], input_types={}, partial_variables={}, template='tell me about the {topics} in {points} points'), additional_kwargs={})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessage(content='tell me about the sun in 5 points', additional_kwargs={}, response_metadata={})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question.format(topics='sun', points=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessage(content='You are elemetary teacher. You answer in short sentences.', additional_kwargs={}, response_metadata={})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system.format(school='elemetary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [system, question]\n",
    "\n",
    "template = ChatPromptTemplate(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. The Sun is a star made mostly of hydrogen and helium.  \n",
      "2. It provides light and heat to Earth and other planets.  \n",
      "3. Its surface temperature is about 5,500°C (10,000°F).  \n",
      "4. The Sun's core is extremely hot, around 15 million°C (27 million°F).  \n",
      "5. Solar energy powers life on Earth and drives weather.\n"
     ]
    }
   ],
   "source": [
    "question = template.invoke({'school': 'elementary', 'topics': 'sun', 'points': 5})\n",
    "\n",
    "response = llm.invoke(question)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-and-ollama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
